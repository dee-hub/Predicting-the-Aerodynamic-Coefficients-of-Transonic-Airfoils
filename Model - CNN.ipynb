{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f64b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0082647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_house_attributes(df, train, test):\n",
    "    # initialize the column names of the continuous data\n",
    "    continuous = [\"ID\", \"Mach No\", \"Angle of Attack\"]\n",
    "    # performin min-max scaling each continuous feature column to\n",
    "    # the range [0, 1]\n",
    "    cs = MinMaxScaler()\n",
    "    trainContinuous = cs.fit_transform(train[continuous])\n",
    "    testContinuous = cs.transform(test[continuous])\n",
    "    # one-hot encode the zip code categorical data (by definition of\n",
    "    # one-hot encoding, all output features are now in the range [0, 1])\n",
    "#    zipBinarizer = LabelBinarizer().fit(df[\"zipcode\"])\n",
    "#    trainCategorical = zipBinarizer.transform(train[\"zipcode\"])\n",
    "#    testCategorical = zipBinarizer.transform(test[\"zipcode\"])\n",
    "    # construct our training and testing data points by concatenating\n",
    "    # the categorical features with the continuous features\n",
    "#    trainX = np.hstack([trainCategorical, trainContinuous])\n",
    "#    testX = np.hstack([testCategorical, testContinuous])\n",
    "    # return the concatenated training and testing data\n",
    "    trainX = trainContinuous\n",
    "    testX = testContinuous\n",
    "    return (trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dd41ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_house_attributes(inputPath):\n",
    "    # initialize the list of column names in the CSV file and then\n",
    "    # load it using Pandas\n",
    "    cols = [\"ID\", \"Mach No\", \"Angle of Attack\", \"Lift Coefficient\", \"Drag Coefficient\"]\n",
    "    df = pd.read_csv(inputPath, sep=\",\", header=None, names=cols)\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22d8e21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Mach No</th>\n",
       "      <th>Angle of Attack</th>\n",
       "      <th>Lift Coefficient</th>\n",
       "      <th>Drag Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># 07/02/2021 09:08:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># The parameters defined in the project are:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># P1 - Mach</td>\n",
       "      <td>P4 - AOA [degree]</td>\n",
       "      <td>P2 - lift</td>\n",
       "      <td>P3 - drag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>DP 67</td>\n",
       "      <td>1.32</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.072957516</td>\n",
       "      <td>0.11930353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>DP 68</td>\n",
       "      <td>1.34</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.071247529</td>\n",
       "      <td>0.11892069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>DP 69</td>\n",
       "      <td>1.36</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.069582417</td>\n",
       "      <td>0.11841808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>DP 70</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.067976107</td>\n",
       "      <td>0.11782868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>DP 71</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.066441971</td>\n",
       "      <td>0.11719117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ID            Mach No  \\\n",
       "0                                             #                 NaN   \n",
       "1                          # 07/02/2021 09:08:41                NaN   \n",
       "2   # The parameters defined in the project are:                NaN   \n",
       "3                                    # P1 - Mach  P4 - AOA [degree]   \n",
       "4                                             #                 NaN   \n",
       "..                                           ...                ...   \n",
       "74                                         DP 67               1.32   \n",
       "75                                         DP 68               1.34   \n",
       "76                                         DP 69               1.36   \n",
       "77                                         DP 70               1.38   \n",
       "78                                         DP 71                1.4   \n",
       "\n",
       "   Angle of Attack Lift Coefficient Drag Coefficient  \n",
       "0              NaN              NaN              NaN  \n",
       "1              NaN              NaN              NaN  \n",
       "2              NaN              NaN              NaN  \n",
       "3        P2 - lift        P3 - drag              NaN  \n",
       "4              NaN              NaN              NaN  \n",
       "..             ...              ...              ...  \n",
       "74              -1     -0.072957516       0.11930353  \n",
       "75              -1     -0.071247529       0.11892069  \n",
       "76              -1     -0.069582417       0.11841808  \n",
       "77              -1     -0.067976107       0.11782868  \n",
       "78              -1     -0.066441971       0.11719117  \n",
       "\n",
       "[79 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_house_attributes('airfoils/data/c5a-data/-1deg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3f2c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_house_images(df, inputPath):\n",
    "    # initialize our images array (i.e., the house images themselves)\n",
    "    images = []\n",
    "    # loop over the indexes of the houses\n",
    "    for i in df.index.values:\n",
    "    # find the four images for the house and sort the file paths,\n",
    "        # ensuring the four are always in the *same order*\n",
    "        basePath = os.path.sep.join([inputPath, \"{}_*\".format(i + 1)])\n",
    "        housePaths = sorted(list(glob.glob(basePath)))\n",
    "# initialize our list of input images along with the output image\n",
    "        # after *combining* the four input images\n",
    "        inputImages = []\n",
    "        outputImage = np.zeros((64, 64, 3), dtype=\"uint8\")\n",
    "        # loop over the input house paths\n",
    "        for housePath in housePaths:\n",
    "            # load the input image, resize it to be 32 32, and then\n",
    "            # update the list of input images\n",
    "            image = cv2.imread(housePath)\n",
    "            image = cv2.resize(image, (32, 32))\n",
    "            inputImages.append(image)\n",
    "            images.append(outputImage)\n",
    "    # return our set of images\n",
    "    return np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "946a42f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-76aba8211f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_house_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'airfoils/data/c5a-data/-1deg.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'airfoils/c5a/AOA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-9098993be0af>\u001b[0m in \u001b[0;36mload_house_images\u001b[0;34m(df, inputPath)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# loop over the indexes of the houses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# find the four images for the house and sort the file paths,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# ensuring the four are always in the *same order*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "load_house_images('airfoils/data/c5a-data/-1deg.csv','airfoils/c5a/AOA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8692b7e",
   "metadata": {},
   "source": [
    "### Models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3973b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "def create_mlp(dim, regress=False):\n",
    "    # define our MLP network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "    # return our model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b9d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "    # define the model input\n",
    "    inputs = Input(shape=inputShape)\n",
    "    # loop over the number of filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "    # if this is the first CONV layer then set the input\n",
    "    # appropriately\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "            # CONV => RELU => BN => POOL\n",
    "            x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "            x = Activation(\"relu\")(x)\n",
    "            x = BatchNormalization(axis=chanDim)(x)\n",
    "            x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "            x = Flatten()(x)\n",
    "            x = Dense(16)(x)\n",
    "            x = Activation(\"relu\")(x)\n",
    "            x = BatchNormalization(axis=chanDim)(x)\n",
    "            x = Dropout(0.5)(x)\n",
    "        # apply another FC layer, this one to match the number of nodes\n",
    "        # coming out of the MLP\n",
    "            x = Dense(4)(x)\n",
    "            x = Activation(\"relu\")(x)\n",
    "        # check to see if the regression node should be added\n",
    "            if regress:\n",
    "                x = Dense(1, activation=\"linear\")(x)\n",
    "        # construct the CNN\n",
    "            model = Model(inputs, x)\n",
    "        # return the CNN\n",
    "            return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031b53cf",
   "metadata": {},
   "source": [
    "### mixed_training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc77dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -d DATASET\n",
      "ipykernel_launcher.py: error: the following arguments are required: -d/--dataset\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dee/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "#from pyimagesearch import datasets\n",
    "#from pyimagesearch import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", type=str, required=True, help=\"path to input dataset of house images\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# construct the path to the input .txt file that contains information\n",
    "# on each house in the dataset and then load the dataset\n",
    "print(\"[INFO] loading house attributes...\")\n",
    "inputPath = os.path.sep.join([args[\"dataset\"], \"HousesInfo.txt\"])\n",
    "df = load_house_attributes(inputPath)\n",
    "# load the house images and then scale the pixel intensities to the\n",
    "# range [0, 1]\n",
    "print(\"[INFO] loading house images...\")\n",
    "images = load_house_images(df, args[\"dataset\"])\n",
    "images = images / 255.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "print(\"[INFO] processing data...\")\n",
    "split = train_test_split(df, images, test_size=0.25, random_state=42)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split\n",
    "# find the largest house price in the training set and use it to\n",
    "# scale our house prices to the range [0, 1] (will lead to better\n",
    "# training and convergence)\n",
    "maxPrice = trainAttrX[\"price\"].max()\n",
    "trainY = trainAttrX[\"price\"] / maxPrice\n",
    "testY = testAttrX[\"price\"] / maxPrice\n",
    "# process the house attributes data by performing min-max scaling\n",
    "# on continuous features, one-hot encoding on categorical features,\n",
    "# and then finally concatenating them together\n",
    "(trainAttrX, testAttrX) = datasets.process_house_attributes(df,\n",
    "\ttrainAttrX, testAttrX)\n",
    "\n",
    "\n",
    "\n",
    "# create the MLP and CNN models\n",
    "mlp = models.create_mlp(trainAttrX.shape[1], regress=False)\n",
    "cnn = models.create_cnn(64, 64, 3, regress=False)\n",
    "# create the input to our final set of layers as the *output* of both\n",
    "# the MLP and CNN\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    "# our final FC layer head will have two dense layers, the final one\n",
    "# being our regression head\n",
    "x = Dense(4, activation=\"relu\")(combinedInput)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "# our final model will accept categorical/numerical data on the MLP\n",
    "# input and images on the CNN input, outputting a single value (the\n",
    "# predicted price of the house)\n",
    "model = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compile the model using mean absolute percentage error as our loss,\n",
    "# implying that we seek to minimize the absolute percentage difference\n",
    "# between our price *predictions* and the *actual prices*\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "model.fit(\n",
    "\tx=[trainAttrX, trainImagesX], y=trainY,\n",
    "\tvalidation_data=([testAttrX, testImagesX], testY),\n",
    "\tepochs=200, batch_size=8)\n",
    "# make predictions on the testing data\n",
    "print(\"[INFO] predicting house prices...\")\n",
    "preds = model.predict([testAttrX, testImagesX])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute the difference between the *predicted* house prices and the\n",
    "# *actual* house prices, then compute the percentage difference and\n",
    "# the absolute percentage difference\n",
    "diff = preds.flatten() - testY\n",
    "percentDiff = (diff / testY) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    "# compute the mean and standard deviation of the absolute percentage\n",
    "# difference\n",
    "mean = np.mean(absPercentDiff)\n",
    "std = np.std(absPercentDiff)\n",
    "# finally, show some statistics on our model\n",
    "locale.setlocale(locale.LC_ALL, \"en_US.UTF-8\")\n",
    "print(\"[INFO] avg. house price: {}, std house price: {}\".format(\n",
    "\tlocale.currency(df[\"price\"].mean(), grouping=True),\n",
    "\tlocale.currency(df[\"price\"].std(), grouping=True)))\n",
    "print(\"[INFO] mean: {:.2f}%, std: {:.2f}%\".format(mean, std))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71866459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
